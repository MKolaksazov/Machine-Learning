{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>DIGIT RECOGNITION</h1>\n",
    "\n",
    "<h2><i>Algorithm for recognition of handwritten digits</i></h2> \n",
    "\n",
    "In many areas of life there is a need for the computers to recognize digits from a paper, including the handwritten digits.\n",
    "<br/>For this purpouse, machine-learning algorithms on the basis of <b>image recognition</b> can be used.\n",
    "<br/>Algorithms for image recognition use <b>convolutional networks</b> with different amount of layers, depending on the complexity of the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>I. Importing keras methods for creating convolutional network from the tensorflow library</h3>\n",
    "\n",
    "<br/>Tensorflow library comes with already created convolutional networks, that are ready to use.\n",
    "<br/>The dataset, used for training is from MNIST (a database of handrwitten digits, 60 000 train and 10 000 test images). It is included inside the keras package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Marko\\ML\\Anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Marko\\ML\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.CSRRD7HKRKC3T3YXA7VY7TAZGLSWDKW6.gfortran-win_amd64.dll\n",
      "D:\\Marko\\ML\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the modules\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import datasets\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Dense,Flatten, Dropout, MaxPooling2D\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Loading the MNIST train dataset inside of a zip object</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
    "union_list = list(zip(xtrain, ytrain))\n",
    "np.random.shuffle(union_list)\n",
    "train_numbers, train_number_labels = zip(*union_list)\n",
    "train_numbers = np.array(train_numbers)\n",
    "train_number_labels = np.array(train_number_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>II. Building the convolutional neural network model</h3>\n",
    "\n",
    "<br/>Layers are ready to use from keras.\n",
    "<br/>The size of the images from the MNIST database was 28, 28 (grayscale).\n",
    "<br/>For image recognition, very usually are used the decreasing convolution networks with relu activation function.\n",
    "<br/>Function, used for classification is softmax, because we have 10 classes of digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Marko\\ML\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Marko\\ML\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(128, (7,7), activation = 'relu', padding = 'Same', input_shape = (28, 28, 1)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, (5, 5), activation = 'relu', padding = 'Same'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, (3, 3), activation = 'relu', padding = 'Same'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>Sparse categorical crossentropy as a loss function is used, because there are the 10 classes of numbers, which are needed to be recognized as a separate individual objects, and the result is encoded as single integer, starting from 0 to the number of classes munis one.\n",
    "<br/>\n",
    "<br/>The Adam optimizer is an adaptive learning rate algorithm thatâ€™s been designed specifically for training deep neural networks. It is the latest trend in deep learning optimization. Adam optimizing algorithm was created on the basis of the stochastic gradient descent with momentum, combined with RMSprop.\n",
    "<br/>\n",
    "<br/>Accuracy metrics calculates the probability of correctly predicted classes from the complete set (softmax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam(lr = 0.0001), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>III. Training the model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Reshaping the train array as an input for the model</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numbers = train_numbers.reshape(-1, 28, 28, 1)\n",
    "xtest = xtest.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The training parameters can be reccorded to a file, so that after trainig they can be accessed afterwards and used without the need to train the model again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "59904/60000 [============================>.] - ETA: 2s - loss: 0.0707 - acc: 0.9778 \n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000002BF3AE3390>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING:tensorflow:From D:\\Marko\\ML\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "60000/60000 [==============================] - 1388s 23ms/sample - loss: 0.0707 - acc: 0.9778\n",
      "Epoch 2/3\n",
      "59904/60000 [============================>.] - ETA: 2s - loss: 0.0551 - acc: 0.9825 \n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000002BF3AE3390>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "60000/60000 [==============================] - 1405s 23ms/sample - loss: 0.0551 - acc: 0.9825\n",
      "Epoch 3/3\n",
      "59904/60000 [============================>.] - ETA: 2s - loss: 0.0441 - acc: 0.9854 \n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000002BF3AE3390>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "60000/60000 [==============================] - 1422s 24ms/sample - loss: 0.0440 - acc: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bfe8e0390>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SKIP IF TRAINED\n",
    "import os\n",
    "import tensorflow as tf\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n",
    "model.fit(train_numbers, train_number_labels, batch_size = 512, epochs = 3,\n",
    "          callbacks = [cp_callback])  # pass callback to training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-trained parameters can be loaded directly to the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0xe478506cc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 1385s 23ms/sample - loss: 1.1667 - acc: 0.7620\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 1382s 23ms/sample - loss: 0.1675 - acc: 0.9478\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 1393s 23ms/sample - loss: 0.1002 - acc: 0.9684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bfd893d30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN MODEL\n",
    "model.fit(train_numbers, train_number_labels, batch_size = 512, epochs = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, there is a classifier used speciffically for recognizing digits, that can be used as a mean to categorize images, based on a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier\n",
    "clf = joblib.load(\"digits_cls.pkl\")\n",
    "\n",
    "# Read the input image \n",
    "im = cv2.imread(\"photo_2.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>IV. Finding the digits inside an image file and recognizing them</h3> \n",
    "\n",
    "<br/>-> first, the image is loaded\n",
    "<br/>-> next, the image is converted to grayscale\n",
    "<br/>-> the threshold and contours are found\n",
    "<br/>-> the individual digits are surrounded by a rectangle\n",
    "<br/>-> the separated images are resized to an appropriate size for the recognition model\n",
    "<br/>-> and, finally, the recognized digits are labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to grayscale and apply Gaussian filtering\n",
    "im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (5, 5), 0)\n",
    "\n",
    "# Threshold the image\n",
    "ret, im_th = cv2.threshold(im_gray, 90, 255, cv2.THRESH_BINARY_INV)\n",
    "#cv2.imshow(\"Resulting Image\", im_th)\n",
    "# Find contours in the image\n",
    "ctrs, hier = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Get rectangles contains each contour\n",
    "rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "\n",
    "# For each rectangular region, calculate HOG features and predict\n",
    "# the digit using Linear SVM.\n",
    "for rect in rects:\n",
    "    # Draw the rectangles\n",
    "    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3) \n",
    "    # Make the rectangular region around the digit\n",
    "    leng = int(rect[3] * 1.6)\n",
    "    pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "    pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "    # Resize the image\n",
    "    roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    '''\n",
    "    #If we want to use the pre-trained model, this code could be uncommented\n",
    "    roi = cv2.dilate(roi, (3, 3))\n",
    "    # Calculate the HOG features\n",
    "    roi_hog_fd = hog(roi, orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    nbr = clf.predict(np.array([roi_hog_fd], 'float64'))\n",
    "    '''\n",
    "    \n",
    "    roismall = roi.reshape(-1,28,28,1)\n",
    "    result = model.predict_classes(roismall)\n",
    "    \n",
    "    cv2.putText(im, str(int(result[0])), (rect[0], rect[1]),cv2.FONT_HERSHEY_DUPLEX, 2, (0, 255, 255), 3)\n",
    "\n",
    "cv2.imshow(\"Resulting Image with Rectangular ROIs\", im)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
